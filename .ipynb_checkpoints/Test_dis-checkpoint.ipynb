{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43293075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd9b1358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geo_data import create_anchor_transform\n",
    "from libs.ConvNeXt.models.convnext import ConvNeXtFeature\n",
    "from models.Distancer import GeoDiscriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e00a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_samples = [ \n",
    "    \"AD_42.528,1.56927.png\", \"AL_41.32654,19.82209.png\", \"AT_47.73333,14.21667.png\", \"BA_43.91194,18.08083.png\", \"BE_50.78263,4.5334.png\", \"BG_42.71231,25.3329.png\", \"BY_53.0245,26.3403.png\", \"CH_46.90981,8.11206.png\", \"CY_35.119479999999996,33.28853.png\", \"CZ_49.73456,15.29297.png\", \"DE_50.39996,9.98198.png\", \"DK_55.80849,10.581669999999999.png\", \"EE_58.63053,25.55402.png\", \"ES_39.68888,-3.50281.png\", \"FI_61.929730000000006,25.15144.png\", \"FR_46.91745,2.49814.png\", \"GB_52.81773,-1.76009.png\", \"GR_37.97451,23.51769.png\", \"HR_44.655,15.95083.png\", \"HU_47.25,19.06667.png\", \"IE_53.32528000000001,-7.979439999999999.png\", \"IS_64.13267,-20.30651.png\", \"IT_43.43218,11.77323.png\", \"LI_47.17556,9.57287.png\", \"LT_55.41019,23.7299.png\", \"LU_49.64506,6.12932.png\", \"LV_57.0619,24.84465.png\", \"MC_43.74041,7.42311.png\", \"MD_47.01095,28.85176.png\", \"ME_42.39333,18.89028.png\", \"MK_41.63468,21.40268.png\", \"MT_35.94556,14.38972.png\", \"NL_52.1738,5.48497.png\", \"NO_62.20631,10.63725.png\", \"PL_51.85225,19.59197.png\", \"PT_39.66978,-8.9958.png\", \"RO_45.68811,24.97548.png\", \"RS_44.24947,20.39613.png\", \"RU_54.1766,37.8881.png\", \"SE_59.06565,15.337470000000001.png\", \"SI_46.05804,14.82515.png\", \"SK_48.56315,19.3029.png\", \"SM_43.90867,12.44808.png\", \"UA_48.57325,29.71874.png\", \"VA_41.90394,12.45401.png\", \"XK_42.54018,20.28793.png\",\n",
    "]\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cdbcc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "trans = transforms.Compose([\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2d2c4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeoDiscriminator(\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (1): GELU(approximate=none)\n",
       "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (3): GELU(approximate=none)\n",
       "    (4): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone = ConvNeXtFeature(depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024], num_classes=46)\n",
    "\n",
    "# checkpoint_model = torch.load(\"convnext_base_22k_224.pth\", map_location='cpu')['model']\n",
    "checkpoint_model = torch.load(\"./logs/cls_final/checkpoint-best.pth\", map_location='cpu')['model']\n",
    "for k in ['head.weight', 'head.bias']:\n",
    "    del checkpoint_model[k]\n",
    "backbone.load_state_dict(checkpoint_model, strict=False)\n",
    "                         \n",
    "model = GeoDiscriminator(1024)\n",
    "# model.load_state_dict(torch.load(\"logs/contrast_final/checkpoint-4.pth\", map_location='cpu')['model'], strict=False)\n",
    "model.load_state_dict(torch.load(\"logs/dis_final/checkpoint-6.pth\", map_location='cpu')['model'], strict=False)\n",
    "\n",
    "backbone.to(device)\n",
    "model.to(device)\n",
    "\n",
    "backbone.eval()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3a57eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_images = []\n",
    "anchor_coords = []\n",
    "data_path = \"./data\"\n",
    "\n",
    "for name in anchor_samples:\n",
    "    _, coord = name[:-4].split(\"_\")\n",
    "    lat, lng = coord.split(\",\")\n",
    "    latlng = np.array([float(lat), float(lng)])\n",
    "    img_path = os.path.join(data_path, name)\n",
    "    img = Image.open(img_path)\n",
    "    anchor_images.append(trans(img))\n",
    "    anchor_coords.append(torch.Tensor(latlng))\n",
    "\n",
    "anchor_images = torch.stack(anchor_images, 0).to(device)\n",
    "anchor_coords = torch.stack(anchor_coords, 0).to(device)\n",
    "with torch.no_grad():\n",
    "    anchor_features = backbone(anchor_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98c6e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def pred_distances(img_path):\n",
    "    _, coord = img_path[:-4].split(\"_\")\n",
    "    lat, lng = coord.split(\",\")\n",
    "    latlng = np.array([float(lat), float(lng)])\n",
    "    \n",
    "    img = Image.open(os.path.join(data_path, img_path))\n",
    "    img_tensor = trans(img).to(device)\n",
    "    img_tensor = img_tensor.unsqueeze(0)\n",
    "    \n",
    "    features = backbone(img_tensor)\n",
    "    \n",
    "    img_coord = torch.Tensor(latlng).unsqueeze(0).to(device)\n",
    "    geo_distance = torch.pairwise_distance(anchor_coords, img_coord.repeat(anchor_coords.shape[0], 1), p=2, keepdim=True).clip(0, 10)\n",
    "\n",
    "    feature_distance = model(torch.cat([anchor_features, features.repeat(anchor_features.shape[0], 1)], dim=-1))\n",
    "    feature_distance = torch.sigmoid(feature_distance)*10\n",
    "    \n",
    "#     print((geo_distance - feature_distance).abs().mean().item()/46)\n",
    "    fea_dis, geo_dis = feature_distance.cpu().numpy(), geo_distance.cpu().numpy()\n",
    "    fea_dis, geo_dis = fea_dis[:,0], geo_dis[:,0]\n",
    "    \n",
    "    gt = geo_dis.argmin()\n",
    "    top5 = fea_dis.argsort()[:5]\n",
    "    \n",
    "    correct = (gt==top5[0])\n",
    "    correct5 = False\n",
    "    for t in top5:\n",
    "        if t==gt:\n",
    "            correct5 = True\n",
    "            break\n",
    "    \n",
    "    return correct, correct5, (geo_distance-feature_distance).mean().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09172820",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./eval\"\n",
    "\n",
    "correct1, correct5 = [], []\n",
    "\n",
    "errors = []\n",
    "for fname in os.listdir(\"./eval\"):\n",
    "    c1, c5, error = pred_distances(fname)\n",
    "    correct1.append(c1)\n",
    "    correct5.append(c5)\n",
    "    errors.append(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bd3c1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3535607"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(errors).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f493e967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(correct1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89a7f2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(correct5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88101dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    _, coord = path[:-4].split(\"_\")\n",
    "    lat, lng = coord.split(\",\")\n",
    "    latlng = np.array([float(lat), float(lng)])\n",
    "    \n",
    "    img = Image.open(os.path.join(data_path, path))\n",
    "    img_tensor = trans(img).to(device)\n",
    "    img_tensor = img_tensor.unsqueeze(0)\n",
    "    return img_tensor, latlng\n",
    "\n",
    "@torch.no_grad()\n",
    "def pred_pair(img1, img2):\n",
    "    img_tensor1, latlng1 = load_img(img1)\n",
    "    img_tensor2, latlng2 = load_img(img2)\n",
    "    \n",
    "    feature1 = backbone(img_tensor1)\n",
    "    feature2 = backbone(img_tensor2)\n",
    "    \n",
    "    img_coord1 = torch.Tensor(latlng1).unsqueeze(0).to(device)\n",
    "    img_coord2 = torch.Tensor(latlng2).unsqueeze(0).to(device)\n",
    "    geo_distance = torch.pairwise_distance(img_coord1, img_coord2, p=2, keepdim=True)\n",
    "\n",
    "    feature_distance = model(torch.cat([feature1, feature2], dim=-1))\n",
    "    feature_distance = torch.sigmoid(feature_distance)*50\n",
    "    \n",
    "#     print((geo_distance - feature_distance).abs().mean().item()/46)\n",
    "    fea_dis, geo_dis = feature_distance.cpu().numpy(), geo_distance.cpu().numpy()\n",
    "    fea_dis, geo_dis = fea_dis[:,0], geo_dis[:,0]\n",
    "    \n",
    "#     for t in range(len(fea_dis)):\n",
    "#         print(f\"{geo_dis[t]:.3f}  ----  {fea_dis[t]:.3f}\")\n",
    "#     print(anchor_coords[top5].mean(0).cpu().numpy())\n",
    "#     print(latlng)\n",
    "    print(np.linalg.norm(anchor_coords.mean(0).cpu().numpy() - latlng)/46)\n",
    "    \n",
    "    return fea_dis, geo_dis, latlng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46a17173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1741782672329096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.], dtype=float32),\n",
       " array([0.00348747], dtype=float32),\n",
       " array([42.54018, 20.28793]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"./data\"\n",
    "pred_pair(\"AD_42.46395,1.5126.png\", \"AD_42.46295,1.50926.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f9963d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
