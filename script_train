#!/bin/sh
#
#  Execute from the current working directory
#$ -cwd
#
#  This is a long-running job
#$ -l inf
#
#  Can use up to 6GB of memory
#$ -l vf=16G
#
#$ -l gpus=1
#
#

nvidia-smi
# python3 main.py --model bit_base --experiment country \
#     --finetune google/bit-50 --imagenet_default_mean_and_std False \
#     --log_dir ./logs/BitR50_cls --output_dir ./logs/BitR50_cls \
#     --input_size 224 --drop_path 0.0 --batch_size 64 \
#     --data_path ./data --lr 3e-5 --min_lr 1e-6 --num_workers 0 --auto_resume False


# python3 main.py --model convnext_base --experiment ivnf \
#     --finetune ./convnext_base_22k_224.pth --dis_criterion mse \
#     --log_dir ./logs/ConvNextB_ivnf_mse --output_dir ./logs/ConvNextB_ivnf_mse \
#     --input_size 224 --drop_path 0.0 --batch_size 16 \
#     --data_path ./data --lr 5e-5 --min_lr 1e-6 --num_workers 0 --auto_resume False

python3 main.py --model convnext_base --experiment latlng \
    --finetune ./convnext_base_22k_224.pth --dis_criterion mse \
    --log_dir ./logs/ConvNextB_latlng --output_dir ./logs/ConvNextB_latlng \
    --input_size 224 --drop_path 0.0 --batch_size 16 \
    --data_path ./data --lr 5e-5 --min_lr 1e-6 --num_workers 0 --auto_resume False

# python3 main.py --model convnext_base --experiment dis_freeze \
#     --finetune ./convnext_base_22k_224.pth --device cuda \
#     --log_dir ./logs/ConvNextB_dis_sigmoid --output_dir ./logs/ConvNextB_dis_sigmoid \
#     --input_size 224 --drop_path 0.0 --batch_size 32 --warmup_steps 10 \
#     --data_path ./data --lr 1e-4 --min_lr 1e-6 --num_workers 0 --auto_resume False

# python3 main.py --model convnext_base --experiment euclidean \
#     --finetune ./convnext_base_22k_224.pth \
#     --log_dir ./logs/ConvNextB_euclidean --output_dir ./logs/ConvNextB_euclidean \
#     --input_size 224 --drop_path 0.0 --batch_size 16 \
#     --data_path ./data --lr 1e-3 --min_lr 1e-5 --num_workers 0

